###############################################################################
language: python
os: linux

addons:
  apt:
    packages:
      # Install ATLAS and LAPACK for numpy/scipy
      - libatlas-dev
      - libatlas-base-dev
      - liblapack-dev
      # Install GEOS for Shapely
      - libgeos-dev
      # Install JPEG library for Pillow>=3.0.0
      - libjpeg-dev

###############################################################################
# Cache data which has to be downloaded on every build.
# This is just for Travis and doesn't do anything on Shippable.
cache:
  directories:
    # Cache files downloaded by pip
    - $HOME/.cache/pip
    - $HOME/Library/Caches/pip
    # Cache our miniconda download.
    - $HOME/Downloads

###############################################################################
env:
  global:
    # Set documentation building option to always be enabled
    # If you only want to do this some of the time, set it with env above.
    - BUILD_DOCS="true"
    # Set flag for whether to use a conda environment
    - USE_CONDA="false"

jobs:
  fast_finish: true

  allow_failures:
    # PR can be deemed okay without waiting for OSX job to finish whole job,
    # except on release branches
    - if: type = pull_request AND NOT branch =~ /^v?\d+(\.\d+)+$/
      os: osx

  include:
    - python: "2.7"
      env:
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="false"

    - python: "2.7"
      env:
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="true"

    - python: "3.5"
      env:
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="false"

    - python: "3.5"
      env:
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="true"

    - python: "3.6"
      env:
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="false"

    - python: "3.7"
      env:
        - TEST_NOTEBOOKS="false"
        - USE_OLDEST_DEPS="false"

    - python: "3.8"
      env:
        - TEST_NOTEBOOKS="false"
        - USE_OLDEST_DEPS="false"

    # OSX --------------------------------
    - name: "Python 3.6.5 on macOS 10.13"
      os: osx
      osx_image: xcode9.4
      language: shell
      env:
        - TRAVIS_PYTHON_VERSION="3.6"
        - TEST_NOTEBOOKS="true"
        - USE_OLDEST_DEPS="false"

    # Only run on release branches
    - if: branch =~ /^v?\d+(\.\d+)+$/
      name: "Python 3.7.3 on macOS 10.14"
      os: osx
      osx_image: xcode10.2
      language: shell
      env:
        - TRAVIS_PYTHON_VERSION="3.7"
        - TEST_NOTEBOOKS="false"
        - USE_OLDEST_DEPS="false"

###############################################################################
# Setup the environment before installing
before_install:
  # Remember the directory where our repository to test is located
  - REPOPATH="$(pwd)" && pwd
  # ---------------------------------------------------------------------------
  # Check which versions of numpy and scipy we are using
  - if [ -f requirements.txt ]; then
      NUMPY_REQUIREMENT="$(grep '^numpy\([!<>=~ ]\|$\)' requirements.txt)";
      echo "NumPy requirement is '$NUMPY_REQUIREMENT'";
      SCIPY_REQUIREMENT="$(grep '^scipy\([!<>=~ ]\|$\)' requirements.txt)";
      echo "SciPy requirement is '$SCIPY_REQUIREMENT'";
    fi;
  # ---------------------------------------------------------------------------
  # If we want to run the tests using the oldest set of dependencies we
  # support, modify any *requirements*.txt files every '>=' becomes '=='.
  # Undo swapping any requirements which say version>=, since they are for
  # our environment markers.
  - if [[ "$USE_OLDEST_DEPS" == "true" ]]; then
      for FILE in *requirements*.txt; do
          sed -e 's/>=/~=/g' $FILE > $FILE.tmp && mv $FILE.tmp $FILE;
          sed -e 's/version\s*~=/version>=/g' $FILE > $FILE.tmp && mv $FILE.tmp $FILE;
      done;
    fi;
  # ---------------------------------------------------------------------------
  # Install conda and set up conda environment
  # The following is based on Minicoda's how-to Travis page
  # http://conda.pydata.org/docs/travis.html
  # - Download miniconda. No need to redownload if we already have the latest version cached.
  # - Install miniconda to the home directory, if it isn't there already.
  # - Add conda to the path and automatically say yes to any check from conda
  # - Remove test environment from conda, if it's still there from last time
  # - Update conda
  - if [[ "$USE_CONDA" == "true" ]]; then
      mkdir -p $HOME/Downloads;
      if [[ "$TRAVIS_PYTHON_VERSION" == "2.7" ]]; then
        MINICONDA_URL=https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh;
      else
        MINICONDA_URL=https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh;
      fi;
      travis_retry wget -c "$MINICONDA_URL" -O "$HOME/Downloads/miniconda.sh";

      if [ ! -d "$HOME/miniconda/bin" ]; then
        if [ -d "$HOME/miniconda" ]; then rm -r "$HOME/miniconda"; fi;
        bash $HOME/Downloads/miniconda.sh -b -p "$HOME/miniconda";
      fi;
      export PATH="$HOME/miniconda/bin:$PATH";
      hash -r;
      conda config --set always_yes yes --set changeps1 no;
      conda config --add channels conda-forge anaconda;

      conda remove -n test-environment --all || echo "No test-environment to remove";

      travis_retry conda update -q conda;
    fi;
  # Useful for debugging any issues with conda
  - conda info -a  || echo "No conda"
  - conda list || echo "No conda"
  #
  # If necessary, check which is the earliest version of numpy and scipy
  # available on conda for this version of python.
  # Because any given version of scipy is only available for a narrow range
  # of numpy versions, we constrain only scipy and not numpy to its oldest
  # possible requirement when scipy is being installed. The version of numpy
  # we end up must still satisfy the original requirement.txt setting, and
  # be from around the time of the oldest supported scipy release.
  - if [[ "$USE_CONDA" == "true" ]] && [[ "$USE_OLDEST_DEPS" == "true" ]]; then
      if [[ "$SCIPY_REQUIREMENT" != "" ]]; then
          SCIPY_VERSION="$(bash
              ./.ci/conda_min_version.sh
              "$SCIPY_REQUIREMENT" "$TRAVIS_PYTHON_VERSION")";
          if [[ "$SCIPY_VERSION" != "" ]]; then
            SCIPY_REQUIREMENT="scipy==$SCIPY_VERSION";
          fi;
      elif [[ "$NUMPY_REQUIREMENT" != "" ]]; then
          NUMPY_VERSION="$(bash
              ./.ci/conda_min_version.sh
              "$NUMPY_REQUIREMENT" "$TRAVIS_PYTHON_VERSION")";
          if [[ "$NUMPY_VERSION" != "" ]]; then
            NUMPY_REQUIREMENT="numpy==$NUMPY_VERSION";
          fi;
      fi;
    fi;
  # Create the conda environment with pip, numpy and scipy installed (if they
  # are in requirements.txt)
  - if [[ "$USE_CONDA" == "true" ]]; then
      conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION
        pip $NUMPY_REQUIREMENT $SCIPY_REQUIREMENT;
    fi;
  # If you get an error from this command which looks like this:
  #   Error: Unsatisfiable package specifications.
  #   Generating hint:
  #   [      COMPLETE      ]|###########| 100%
  #   Hint: the following packages conflict with each other:
  #     - numpy >=1.9.0
  #     - scipy ==0.12.0
  #
  # This is because you have constrained the numpy version in requirements.txt
  # to a more recent set of values (e.g. numpy>=1.9.0) than the scipy
  # constraint (e.g. scipy>=0.12.0). The USE_OLDEST_DEPS code has
  # looked up the oldest compatible version available on conda (scipy==0.12.0)
  # but there is no numpy version for this which matches your constraint.
  #
  # You can resolve this by doing a search of the conda packages available
  #   conda search scipy
  # and changing your scipy constraint to be scipy>=x.y.z, where x.y.z is the
  # oldest version which has a matching numpy version in its buildstring.
  # To resolve the example, we look for the first scipy version which has
  # 'np19' in its buildstring, and find it is scipy version 0.14.0, so we
  # update the requirements.txt file to have 'scipy>=0.14.0' instead of
  # 'scipy>=0.12.0'.
  #
  # Activate the test environment
  - if [[ "$USE_CONDA" == "true" ]]; then source activate test-environment; fi;

###############################################################################
# install requirements
install:
  # Make a list of all requirements
  - cat requirements.txt requirements-dev.txt > requirements_all.txt
  # Conditionally install the packages which are needed for building docs
  - if [[ "$BUILD_DOCS" == "true" ]]; then
      cat requirements_docs.txt >> requirements_all.txt;
    fi
  # Conditionally install the packages which are needed for plotting
  # Also, tell matplotlib to use the agg backend and not X server
  - if [[ "$TEST_NOTEBOOKS" == "true" ]]; then
      export MPLBACKEND="agg";
      cat requirements_plots.txt >> requirements_all.txt;
      echo "sima" >> requirements_all.txt;
      echo "suite2p" >> requirements_all.txt;
    fi
  # Show the resulting list of packages
  - cat requirements_all.txt;
  # ---------------------------------------------------------------------------
  # If we are using a conda environment, install as much as we can in conda
  # Anything we can't install into conda will be installed with pip later
  - if [[ "$USE_CONDA" == "true" ]]; then
      while read REQUIREMENT;
        do conda install $REQUIREMENT || echo "$REQUIREMENT not on conda";
      done < requirements_all.txt;
    fi;
  # ---------------------------------------------------------------------------
  # Installation with pip will handle all packages if we aren't using conda,
  # or all packages which couldn't be installed with conda if we were using it.
  # Do numpy and scipy requirements first, because some packages need them
  # in order for the pip install to complete.
  - sed -n '/^\(num\|sci\)py\([!<>=~ ]\|$\)/p' requirements_all.txt > .requirements_first.txt;
    cat .requirements_first.txt;
    pip install -r .requirements_first.txt;
  # Install required packages listed in requirements.txt. We install this
  # with the upgrade ('-U') flag to ensure we have the most recent version of
  # the dependency which is compatible with the specification.
  - pip install --no-deps --upgrade -r requirements_all.txt;
    pip install -r requirements_all.txt;
  # ---------------------------------------------------------------------------
  # Install our own package
  - python setup.py develop

###############################################################################
before_script:
  # Double-check we are still in the right directory
  - pwd
  # Check what python packages we have installed
  - conda info -a || echo "No conda"
  - which python
  - python --version
  - which ipython || echo "No ipython found"
  - conda env export > environment.yml && cat environment.yml || echo "No conda"
  - pip freeze
  # ---------------------------------------------------------------------------
  # Remove any cached results files from previous build, if present
  - rm -f testresults.xml;
    rm -f coverage.xml;
    rm -f .coverage;
  # ---------------------------------------------------------------------------
  # Set up folders for test results on Shippable
  - if [ "$SHIPPABLE" = "true" ]; then
      rm -fr shippable;
      mkdir -p shippable/testresults;
      mkdir -p shippable/codecoverage;
    fi;

###############################################################################
# commands to run test scripts
script:
  - python --version;
    if [[ "$NUMPY_REQUIREMENT" != "" ]]; then
      python -c "import numpy; print('numpy %s' % numpy.__version__)";
    fi;
    if [[ "$SCIPY_REQUIREMENT" != "" ]]; then
      python -c "import scipy; print('scipy %s' % scipy.__version__)";
    fi;
  # ---------------------------------------------------------------------------
  # Test the main code base
  - py.test --cov=fissa --cov-report term --cov-report xml --cov-config .coveragerc --junitxml=testresults.xml
  # Build the documentation
  - if [[ "$BUILD_DOCS" == "true" ]]; then
      make -C docs html;
    fi;
  # Test the notebooks
  - if [[ "$TEST_NOTEBOOKS" == "true" ]]; then
      py.test --nbsmoke-run ./examples/;
      py.test --nbsmoke-lint ./examples/;
    fi;

###############################################################################
# commands to run after tests are done
after_script:
  # Show where we ended up
  - pwd
  # Go back to the repository directory, just in case
  # Show what results files there are
  - cd ${REPOPATH} && ls -alh;
  # ---------------------------------------------------------------------------
  # Move results and coverage files into appropriate places
  - if [ "$SHIPPABLE" = "true" ] && [ -f testresults.xml ]; then
      mv testresults.xml shippable/testresults/;
    fi;
    if [ "$SHIPPABLE" = "true" ] && [ -f coverage.xml ]; then
      cp coverage.xml shippable/codecoverage/;
    fi;

###############################################################################
after_success:
  # Only run coveralls on Travis. When running on a public Travis-CI, the
  # repo token is automatically inferred, but to run coveralls on Shippable
  # the repo token needs to be specified in a .coveralls.yml or as an
  # environment variable COVERALLS_REPO_TOKEN. This should be kept hidden
  # from public viewing, either by encrypting the token or running on a
  # private build.
  # We ignore coveralls failures because the coveralls server is not 100%
  # reliable and we don't want the CI to report a failure just because the
  # coverage report wasn't published.
  - if [ "$TRAVIS" = "true" ] && [ "$SHIPPABLE" != "true" ]; then
      pip install coveralls;
      travis_retry coveralls || echo "Coveralls push failed";
      pip install codecov;
      travis_retry codecov || echo "Codecov push failed";
    fi;

###############################################################################
# Steps to take before archiving on Shippable (does nothing on Travis)
before_archive:
  # Have shippable archive the environment.yml artifact by putting it in
  # the REPO/shippable folder. This is available to download as a tar file for
  # each build.
  # Since this build was successful, you can share it for users to install from
  # with the command `conda env create -f environment.yml` and know they have
  # a working build.
  # If you want to save this file on Travis, you will need to turn on the
  # artifacts addon (or do something else with it). See here for details
  # https://docs.travis-ci.com/user/uploading-artifacts/
  - if [ "$SHIPPABLE" = "true" ] && [ -f environment.yml ]; then
      cp environment.yml shippable/;
    fi;

###############################################################################
# Enable archiving of artifacts on Shippable (does nothing on Travis)
archive: true
